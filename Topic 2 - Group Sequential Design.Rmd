---
title: "Group Sequential Design"
output: html_document
---

## Reference 

  + https://www.biostat.washington.edu/sites/default/files/modules//2016_SISCR_9_3.pdf
  + R package [RCTdesgn](http://www.rctdesign.org/Welcome.html)
  

## Adding interim analysis
  
  + Power decreases (unless sample size is increased)
  + Expected sample size gets smaller
  + With increasing number of interim analysis, the total average sampel number (ASN) decreases (see slide 8 of Reference 1)
  
### Reasons for stopping
  
  + Stop for either efficacy or futility
      + this means stopping for both null and alternative hypothesis
      + Symmetric power for futility and efficacy decisions
      + Symmetric ASN for futility and efficacy decisions
  + Stop only for futility (null hypothesis)
      + Power for efficacy may decrease
      + ASN reduced for futility, but not for efficacy
  + Stop only for efficacy (alternative hypothesis)
      + Power for efficacy may decrease
      + ASN reduced for efficacy, but not for futility
  
### Selecting degree of early conservatism

  + O'Brien-Flemming design shows early conservatism (i.e., relatively difficult to stop at early interim analyses)
  + Pocock design is not conservative in early decisions (i.e., relatively easy to stop at early interim analyses)
  + Degree of conservatism does not have to be symmetric.
  
### Effect of early conservatism
  
  + More conservatism (harder to stop at early analyses)
      + Tends to give higher power
      + Tends to give larger ASN
  + Less conservatism (easier to stop)
      + Tends to decrease power
      + Tends to reduce ASN
  + Asymmetric conservatism
      + Often need early sensitivity for harm, but not conservatism for efficacy
      
      
      
### Design Evaluation
  + Elements that are established in the fixed sample design
      + Endpoint, prob model, functional, contrast
      + Maximal information (sample size, $N_j$; design alternative hypotheses)
      + Statistical standard for evidence ($\alpha$ level)
  + Evaluation of group sequential design:
      + sample size is a random variable; characteristics of interest:
          + Mean (Average sample size - ASN)
          + Quantiles (median, Q1, Q3)
          + Power curve
          + Power for fixed $N_j$
          + $N_j$ for fixed power
          + Stopping probability at each interim analysis
          + Inference at the boundary: what is the statistical inference (point estimate, interval estimate, and p-value) that would be reported if the trial is stopped?
  + Iterate: modify the stopping rules until an acceptable mixed of properties is found
  
  
## General Behavior of Group Sequential Design  
  + For any given sample size, adding interim analyses reduces power
  + For any given power, adding interim analyses increases the sample size
  + Having fewer interim analyses: 
      + leads to properties (maxmial sample size, power, etc) that are closer to those of a fixed sample study
      + however, ASN may be larger and stopping probabilities lower
  + Having more earlier conservatism:
      + leads to properties (maximal sample size, power, etc) that are closer to those of a fixed sample study
      + however, ASN may be larger and stopping probabilities lower.
      
# Theory on Group Sequential Design

## Reference 

  + Repeated Significance Tests on Accumulating Data, **P. Armitage, C. K. McPherson and B. C. Rowe**,  *Journal of the Royal Statistical Society. Series A (General) Vol. 132, No. 2 (1969), pp. 235-244*
  + [Group Sequential Methods in the Design and Analysis of Clinical Trials](ftp://maia-2.biostat.wisc.edu/pub/chappell/641/papers/paper33.pdf), **Stuart J. Pocock**, *Biometrika, Vol. 64, No. 2 (Aug., 1977), 191-199.* 
  + [A Multiple Testing Procedure for Clinical Trials](ftp://maia-2.biostat.wisc.edu/pub/chappell/641/papers/paper34.pdf), **Peter C. O'Brien and Thomas R. Fleming**, *Biometrics, Vol. 35, No. 3 (Sep., 1979), 549-556.*
  
  
## Framework
This framework of GSD is based on the references listed above. For simplicity, the theory is discussed in the context of normal distribution; The results however, can be generalized into other distribution families. 

### Summary based on Armitage 1969
Consider an experiment consisting of a series of observations $X_1$, $X_2$, $\ldots$, $X_n$ on random variables that, under the null hypothesis, are i.i.d. $N(0, 1)$. After each observation, the experimenter uses the cumulative sum 
\begin{equation}\label{eq:eq1}
S_n = \sum_{i=1}^nX_i
\end{equation}
to test the null hypothesis. He stops sampling when, for the first time, 
\begin{equation}\label{eq:eq2}
|S_n|\geq y_n, 
\end{equation}
where $y_n = k\sqrt{n}$ for some constant $k$. The value of $n$ at which the experiment stops is denoted by $m$. Usually, $k$ is chosen to correspond to a non-sequential test for $S_n$ at a selected significance level. For two-sided level $2\alpha$, with the usual notation for the normal integral, $\Phi(k) = 1-\alpha$. 

Now the problem boils down to finding the distribution of $m$. Let $f_n(s_n)$ be the probability density function of $S_n$ in the sequential procedure. We then have 
\begin{equation}
f_n(s_n) =\left\{ 
  \begin{array}{ll}
  \int_{-y_{n-1}}^{y_{n-1}}f_{n-1}(u)\frac{1}{\sqrt{2\pi}}\exp\{-\frac{1}{2}(s_n-u)^2\}du, ~~ -y_n\leq s_n\leq y_n \\
    0, ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ ~~ \text{otherwise}
  \end{array}
  \right.
\end{equation}
Which is obtained by convolution formula given that $S_{n-1}\sim f_{n-1}(s_{n-1})$, $X_n\sim N(0, 1)$ and $S_n = X_n + S_{n-1}$. 

The density function $f_n$ can be defined recursively with $f_1$ being the density for standard normal distribution 
  

  